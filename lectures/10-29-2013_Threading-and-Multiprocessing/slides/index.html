<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<meta name="viewport" content="width=1024, user-scalable=no">

	<title>Isilon System Development with Python, Week 7 : Threading &amp; Multiprocessing</title>
	
	<!-- Required stylesheet -->
	<link rel="stylesheet" href="core/deck.core.css">
	
	<!-- Extension CSS files go here. Remove or add as needed. -->
	<link rel="stylesheet" href="extensions/goto/deck.goto.css">
	<link rel="stylesheet" href="extensions/menu/deck.menu.css">
	<link rel="stylesheet" href="extensions/navigation/deck.navigation.css">
	<link rel="stylesheet" href="extensions/status/deck.status.css">
	<link rel="stylesheet" href="extensions/hash/deck.hash.css">
	<link rel="stylesheet" href="extensions/scale/deck.scale.css">

	<!-- Style theme. More available in /themes/style/ or create your own. -->
    <!-- default
	<link rel="stylesheet" href="themes/style/neon.css">
    -->
	<link rel="stylesheet" href="themes/style/web-2.0.css">

	
	<!-- Transition theme. More available in /themes/transition/ or create your own. -->
    <!--
	<link rel="stylesheet" href="themes/transition/fade.css">
    -->
	<link rel="stylesheet" href="themes/transition/horizontal-slide.css">
	
	<!-- Required Modernizr file -->
	<script src="modernizr.custom.js"></script>
</head>
<body class="deck-container">

<!-- Begin slides. Just make elements with a class of slide. -->

<section class="slide">
	<h2>Python 300: Threading &amp; Multiprocessing</h2>
    <p>October 29, 2013</p>
    <p>Joseph Sheedy</p>
    <p><i>joseph.sheedy@gmail.com</i></p>
    <p>Git repository:  <a href="https://github.com/UWPCE-PythonCert/Python300-SystemDevelopmentWithPython" target="_blank">https://github.com/UWPCE-PythonCert/Python300-SystemDevelopmentWithPython</a></p>
</section>



<section class="slide">
    <h2>Threading / multiprocessing</h2>
    <h3>Today's topics</h3>
    <ul>
        <li>Review of argparse</li>
        <li>Threading / multiprocessing motivation and options</li>
        <li>threading module
        <li>multiprocessing module
        <li>other options
    </ul>
</section>

<section class="slide">
    <h2>argparse</h2>
    <p>A module for handling command line arguments like</p>
    <p><code>% command.py arg1 --x 9 --y 10 </code></p>
    <p>Command line arguments are accessible directly via sys.argv
    <p>Manually parsing sys.argv gets difficult with optional parameters
    <p>argparse is easy for simple cases, and possible for complex ones
    <p>Features:</p>
    <ul>
        <li>position independent optional arguments
        <li>type and range validation
        <li>subcommands
    </ul>
<p><pre><code>
# basic usage
parser = argparse.ArgumentParser()
parser.add_argument('x', type=int, help="x value")
args = parser.parse_args()
print args.x
</code></pre></p>
<p>
    <a target="_blank" href="http://docs.python.org/2.7/library/argparse.html">http://docs.python.org/2.7/library/argparse.html</a>
</p>

</section>
<section class="slide">
    <h2>argparse in action</h2>
    <p>Add() is back, as a command line utility</p>
    <p>Here we add two positional arguments
<pre><code>
import argparse

parser = argparse.ArgumentParser(description='add app')
parser.add_argument('x', type=int, help='x value')
parser.add_argument('y', type=int, help='y value')

args = parser.parse_args()

print args.x + args.y
</code></pre>
</section>

<section class="slide">
    <h2>argparse optional arguments</h2>
    <p>Add '--' in front of arguments to make them optional
    <p>If you want an --option to be required, add required=True
    <p>If you want an option prefix different than '--', add prefix_chars='-+' to your ArgumentParser <a target="_blank" href="http://docs.python.org/2.7/library/argparse.html#prefix-chars">(see docs)</a>
    <p>ArgumentParser objects associate command-line arguments with actions. These actions can do just about anything with the command-line arguments associated with them, though most actions simply add an attribute to the object returned by parse_args()
    <p>The default action is 'store', which will assign the value to an attribute on the object
    <p>Additional actions:
    <ul>
        <li>store_const='FOO' - stores the constant value in the attribute
        <li>append - appends the value to a list, useful for arguments that can be specified multiple times
        <li>count - keeps track of how many times the argument was given (e.g. "-v -v -v")
    </ul>
<pre><code>
parser.add_argument('--verbose', action='store_true', help="make verbose") 
</code></pre>
</section>

<section class="slide">
    <h2>Argparse nargs</h2>
    <p>Accept an arbitrary number of arguments with the nargs kwarg</p>
<pre><code>
# collect 2 arguments
parser.add_argument('foo', nargs=2)
</code></pre>
<pre><code>
# collect all arguments, e.g. ./program.py 4 5 6
parser.add_argument('foo', nargs='*')
</code></pre>
<pre><code>
# collect all arguments, returning 
# an error if there's not at least one, 
# e.g. ./program.py 4 5 2
parser.add_argument('foo', nargs='+')
</code></pre>
</section>

<section class="slide">
    <h2>FileType objects</h2>
    <p>input and output file streams can be handled with type=FileType
    <p>argparse.FileType(mode, buffer_size)
<pre><code>
parser.add_argument('--output', type=argparse.FileType('wb', 0))
</code></pre>
    <p>The argument '-' is automatically converted to sys.stdin for readonly FileTypes, and sys.stdout for writable FileTypes

</section>

<section class="slide">
    <h2>Exercise</h2>
    <p>Create a script which:
        <ul>
            <li>reads stdin
            <li>inserts the line number in from of each line 
            <li>outputs to the file or stdout as specified on the command line via argparse
        </ul>
</section>

<section class="slide">
    <h2>argparse: custom Actions</h2>
    <p>You may also do arbitrary handling by passing an object which subclasses argparse.Action with a definition of __call__(parser, namespace, values, option_string)
<pre><code>
import argparse

class FooAction(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, values)
        print '%r %r %r' % (namespace, values, option_string)

parser = argparse.ArgumentParser()
parser.add_argument('--foo', action=FooAction)
parser.add_argument('bar', action=FooAction)
args = parser.parse_args('1 --foo 2'.split())
print args.bar
</code></pre>
</section>

<section class="slide">
    <h2>subcommands </h2>
    <p>Split up functionality into subcommands
    </p>
<p><pre><code>
import argparse

parser = argparse.ArgumentParser(description='add app')
subparsers = parser.add_subparsers(help='sub command')

null_parser = subparsers.add_parser('null', help='null')

echo_parser = subparsers.add_parser('echo', help='echo')
echo_parser.add_argument('message', nargs='*', help='values')

args = parser.parse_args()
print vars(args).get('message', "null")
</code></pre></p>
</section>

<section class="slide">
    <h2>subcommands </h2>
    <p>slightly more generalized math script with subcommands</p>
<pre>
<code>
import argparse

def add(x,y):
    return x+y

def double(x):
    return 2*x

def handle_sum(*args):
    return sum(args)

parser = argparse.ArgumentParser(description='add app')
parser.add_argument('--verbose', '-v', action='store_true', help='verbose')

subparsers = parser.add_subparsers(help='sub command')

add_parser = subparsers.add_parser('add', help='add')
add_parser.add_argument('x', type=float, nargs=2, help='values')
add_parser.set_defaults(func=add)

sum_parser = subparsers.add_parser('sum', help='sum')
sum_parser.add_argument('x', type=float, nargs='+', help='values')
sum_parser.set_defaults(func=handle_sum)

double_parser = subparsers.add_parser('double', help='double')
double_parser.add_argument('x', type=float, nargs=1, help='value')
double_parser.set_defaults(func=double)

args = parser.parse_args()
if args.verbose:
    print "executing command"

print args.func(*(args.x))
</code>
</pre>
</section>

<section class="slide">
    <h2>End of argparse overview</h2>
    <p>This should cover most of your argument processing needs.  For more detailed usage:</p>
    <a target="_blank" href="http://docs.python.org/2.7/library/argparse.html">http://docs.python.org/2.7/library/argparse.html</a>
</section>

<section class="slide">
    <h2>Motivations for parallel execution</h2>
    <ul>
        <li>Performance
        <ul>
            <li>Limited by <a target="_blank" href="http://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's Law</a>
        </ul>
        <li>Event handling
            <ul>
                <li>Network applications 
                <li>user interfaces
            </ul>
    </ul>
    <p>Parallel programming can be hard!
    <p>If your problem can be solved sequentially, consider the costs and benefits before going parallel.

</section>

<section class="slide">
    <h2>Parallelization strategy</h2>
    <ol>
        <li>Break problem down into chunks
        <li>Execute chunks in parallel
        <li>Reassemble output of chunks into result
    </ol>
    <img width="500" src="images/OPP.0108.gif" />
</section>

<section class="slide">
    <h2>Parallelization strategy for performance</h2>
    <p>
        <ul>
            <li>Not every problem is parallelizable
            <li>There is an optimal number of threads for each problem in each environment, so make it tunable.
            <li>Working concurrently opens up a Pandora's box of synchronization issues
            <li>Synchronizing threads:
            <ul>
                <li>locks
                <li>queues
                <li>signaling/messaging mechanisms
            </ul>
        </ul>
    </p>
</section>

<section class="slide">
    <h2>Threads versus processes in Python</h2>
    <h3>Processes</h3>
    <p>A process contains all the instructions and data required to execute independently
    <p>The Python interpreter isn't lightweight!
    <p>Communication between processes can be achieved via multiprocessing.Queue, multiprocessing.Pipe, and regular IPC</p>
    <p>processes require multiple copies of the data, or expensive IPC to access it</p>
    <p>data moved between processes must be pickleable</p>

    <h3>Threads</h3>
    <p>Threads are lightweight processes, run in the address space of an OS process.
    <p>Threads share the address space of the parent process.  This allows
    access to data in the same scope.</p>
    <p>Python threads are true OS level threads</p>
    <p>Threads can not gain the performance advantage of multiple processors due to the Global Interpreter Lock (GIL)</p>
    <p>But the GIL is released during IO, allowing IO bound processes to benefit from threading</p>

</section>

<section class="slide">
    <h2>GIL</h2>
    <h3>Global Interpreter Lock</h3>
    <p>This is a lock which must be obtained by each thread before it can execute, ensuring thread safety</p>
    <img width="100%" src="images/gil.png" />
    <p>The GIL is released during IO operations, so threads which spend time waiting on network or disk access can 
    enjoy performance gains</p>
    <p>Some alternative Python implementations such as Jython and IronPython have no GIL
    <p>cPython and PyPy have one
    <p>Launch multiple processes to speed up CPU bound operations.  Luckily, this is easy with the multiprocessing module.</p>

    <ul>
        <li><a target="_blank" href="http://wiki.python.org/moin/GlobalInterpreterLock">http://wiki.python.org/moin/GlobalInterpreterLock</a></li>
        <li><a target="_blank" href="http://docs.python.org/2/c-api/init.html#threads">http://docs.python.org/2/c-api/init.html#threads</a></li>
    </ul>
</section>

<section class="slide">
    <h2>posted without comment</h2>
    <img width="500" src="images/killGIL.jpg" />
</section>

<section class="slide">
    <h2>A real CPU bound problem</h2>

    <p>
        Numerically integrate the function
        <a target="_blank" href="http://www.wolframalpha.com/input/?i=x%5E2">y = x<sup>2</sup></a>
        from 0 to 10.
    </p>
    <p>
        <img src="images/x2.png" />
        <br />
        <a target="_blank" href="http://www.wolframalpha.com/input/?i=int%28x%5E2%2C0%2C10%29">Solution</a>
    </p>
</section>
<section class="slide">
    <h2>Poor man's parallel execution example</h2>
<p>
Consider the following code from last week
<pre><code>
def f(x):
    return x**2

def integrate_f(a, b, N):
    s = 0
    dx = (b-a)/N
    for i in xrange(N):
        s += f(a+i*dx)
    return s * dx
</code></pre>
</p>
<p>Break down the problem into parallelizable chunks, then add the results together:</p>
<pre><code>
((python integrate_main.py 0 5 1000000) &) ; ((python integrate_main.py 5 10 1000000) & )
</code></pre>
</section>

<section class="slide">
    <h2>the threading module</h2>
    <p>starting threads is the easy part</p>
<pre><code>
import sys
import threading
import time

def func():
    for i in xrange(5):
        print "hello from thread %s" % threading.current_thread().name
        time.sleep(1)

threads = []
for i in xrange(3):
    thread = threading.Thread(target=func, args=())
    thread.start()
    threads.append(thread)

for thread in threads:
    thread.join()

</code></pre>
<ul>
    <li>The process will exit when the last non-daemon thread exits.   
    <li>You can block and wait for a thread to exit with thread.join()   
</ul>
</section>

<section class="slide">
    <h2>Managing thread results</h2>
    <p>We need a thread safe way of storing results from multiple threads of execution.  That is provided by the Queue module. </p>
    <p>Queues allow multiple producers and multiple consumers
    <p>Size of the queue is managed with the maxsize kwarg, it will block consumers if empty and block producers if full
    <p>If maxsize is less than or equal to zero, the queue size is infinite

<p><pre><code>
from Queue import Queue
q = Queue(maxsize=10)
q.put(37337)
block = True
timeout = 2
print q.get(block, timeout)
</code></pre></p>
    <p>
    <ul>
        <li><a target="_blank" href="http://docs.python.org/2/library/threading.html">http://docs.python.org/2/library/threading.html</a>
        <li><a target="_blank" href="http://docs.python.org/2/library/queue.html">http://docs.python.org/2/library/queue.html</a>
    </ul>
    </p>
</section>

<section class="slide">
    <h2>Other Queue types</h2>
    <p>Queue.LifoQueue - Last In, First Out
    <p>Queue.PriorityQueue - Lowest valued entries are retrieved first
    <p>One pattern for PriorityQueue is to insert entries of form data by inserting the tuple: (priority_number, data)
    
</section>

<section class="slide">
    <h3>threading example</h3>
<p><pre>
#!/usr/bin/env python

import argparse
import os
import sys
import threading
import Queue

sys.path.append(os.path.join(os.path.dirname(__file__), ".."))
from integrate.integrate import integrate, f
from decorators.decorators import timer

@timer
def threading_integrate(f, a, b, N, thread_count=2):
    """break work into two chunks"""
    N_chunk = int(float(N) / thread_count)
    dx = float(b-a) / thread_count

    results = Queue.Queue()

    def worker(*args):
        results.put(integrate(*args))

    threads = []
    for i in xrange(thread_count):
        x0 = dx*i
        x1 = x0 + dx
        thread = threading.Thread(target=worker, args=(f, x0, x1, N_chunk))
        thread.start()
        print "Thread %s started" % thread.name
        # thread1.join()

    return sum( (results.get() for i in xrange(thread_count) ))

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='integrator')
    parser.add_argument('a', nargs='?', type=float, default=0.0)
    parser.add_argument('b', nargs='?', type=float, default=10.0)
    parser.add_argument('N', nargs='?', type=int, default=10**7)
    parser.add_argument('thread_count', nargs='?', type=int, default=2)

    args = parser.parse_args()
    a = args.a
    b = args.b
    N = args.N
    thread_count = args.thread_count

    print "Numerical solution with N=%(N)d : %(x)f" % \
            {'N': N, 'x': threading_integrate(f, a, b, N, thread_count=thread_count)}
</pre></p>
</section>

<section class="slide">
    <h2>Subclassing Thread</h2>
    <p>Subclass Thread and override the run method</p>
<pre><code>
import threading

class MyThread(threading.Thread):
    def run(self):
        print "hello from %s" % threading.current_thread().name

thread = MyThread()
thread.start()
</code></pre>
</section>

<section class="slide">
    <h2>Locks</h2>
    <p>Lock objects allow threads to control access to a resource until they're done with it</p>
<p><pre><code>
import threading
import time

lock = threading.Lock()

def f():
    lock.acquire()
    print "%s got lock" % threading.current_thread().name
    time.sleep(1)
    lock.release()

threading.Thread(target=f).start()
threading.Thread(target=f).start()
threading.Thread(target=f).start()
    
</code></pre></p>
</section>
<section class="slide">
    <h2>threading.RLock</h2>
    <p>A reentrant lock can be acquired multiple times by the same thread</p>
    <p>Lock.release() must be called the same number of times as Lock.acquire() by that thread</p>
    <p>Useful for recursive algorithms, a thread-specific count of the locks is maintained
</section>

<section class="slide">
    <h2>threading.Semaphore</h2>
    <p>Like an RLock, but in reverse
    <p>A Semaphore is given an initial counter value, defaulting to 1
    <p>Each call to acquire() decrements the counter, release() increments it
    <p>If acquire() is called on a Semaphore with a counter of 0, it will block until the Semaphore counter is greater than 0.
    <p>Useful for controlling the maximum number of threads allowed to access a resource simultaneously
<p>
<a target="_blank" href="http://en.wikipedia.org/wiki/Semaphore_(programming)">http://en.wikipedia.org/wiki/Semaphore_(programming)</a>
</p>
</section>
<section class="slide">
    <h2>Locking Exercise</h2>
    <p>find examples/lock/stdout_writer.py</p>
    <p>multiple threads in the script write to stdout, and their output gets jumbled
    <p>Add a locking mechanism to give each thread exclusive access to stdout 
</section>

<section class="slide">
    <h2>multiprocessing</h2>

    <p>multiprocessing provides an API very similar to threading, so the transition is easy</p>
    <p>use multiprocessing.Process instead of threading.Thread
<p><pre><code>
import multiprocessing
import os
import time

def func():
    print "hello from process %s" % os.getpid()
    time.sleep(1)

proc = multiprocessing.Process(target=func, args=())
proc.start()
proc = multiprocessing.Process(target=func, args=())
proc.start()
</code></pre></p>
</section>

<section class="slide">
    <h2>Differences with threading</h2>
    <p>multiprocessing has its' own multiprocessing.Queue which handles interprocess communication 
    <p>Also has its' own versions of Lock, RLock, Semaphore
<pre><code>
from multiprocessing import Queue, Lock
</code></pre>
</section>

<section class="slide">
    <h2>Pooling</h2>
    <p>a processing pool contains worker processes with only a configured number running at one time
    <p>
<pre><code>
from multiprocessing import Pool
pool = Pool(processes=4)
</code></pre>
<p>The Pool module has several methods for adding jobs to the pool
    <ul>
        <li>apply_async(func[, args[, kwargs[, callback]]]) 
        <li>map_async(func, iterable[, chunksize[, callback]])
    </ul>
</p>
</section>
<section class="slide">

    <h2>Pooling example</h2>
<pre><code>
from multiprocessing import Pool

def f(x):
    return x*x

if __name__ == '__main__':
    pool = Pool(processes=4)              # start 4 worker processes

    result = pool.apply_async(f, (10,))    # evaluate "f(10)" asynchronously
    print result.get(timeout=1)           # prints "100" unless your computer is *very* slow

    print pool.map(f, range(10))          # prints "[0, 1, 4,..., 81]"

    it = pool.imap(f, range(10))
    print it.next()                       # prints "0"
    print it.next()                       # prints "1"
    print it.next(timeout=1)              # prints "4" unless your computer is *very* slow

    import time
    result = pool.apply_async(time.sleep, (10,))
    print result.get(timeout=1)           # raises TimeoutError
</code></pre>
<p><a target="_blank" href="http://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool">http://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool</a>
</section>

<section class="slide">
    <h2>Other options</h2>
    <p>Traditionally, concurency has been achieved through multiple process communication and in-process threads, as we've seen</p>
    <p>Another strategy is through micro-threads, implemented via coroutines and a scheduler
    <p>A coroutine is a generalization of a subroutine which allows multiple entry points for suspending and resuming execution
    <p>the threading and the multiprocessing modules follow a <a target="_blank" href="http://en.wikipedia.org/wiki/Preemption_(computing)">preemptive multitasking model</a>
    <p>coroutine based solutions follow a <a target="_blank" href="http://en.wikipedia.org/wiki/Computer_multitasking#Cooperative_multitasking.2Ftime-sharing">cooperative multitasking model</a>
    <ul>
        <li><a href="http://dabeaz.com/coroutines/">http://dabeaz.com/coroutines/, A Curious Course on Coroutines and Concurrency</a>
        <li><a href="http://en.wikipedia.org/wiki/Coroutine">http://en.wikipedia.org/wiki/Coroutine</a>
    </ul>

</section>

<section class="slide">
    <h2>With send(), a generator becomes a coroutine</h2>

<p><pre><code>
def coroutine(n):
    try:
        while True:
            x = (yield)
            print n+x
    except GeneratorExit:
        pass

targets = [
 coroutine(10),
 coroutine(20),
 coroutine(30),
]

for target in targets:
    target.next()

for i in range(5):
    for target in targets:
        target.send(i)
</code></pre></p>
<p>
    <a target="_blank" href="http://dabeaz.com/coroutines/Coroutines.pdf">http://dabeaz.com/coroutines/Coroutines.pdf</a>
</p>
</section>

<section class="slide">
    <h2>Packages using coroutines for micro threads</h2>
    <p>By "jumping" to parallel coroutines, our application can simulate true threads. 
    <p>Creating the scheduler which does the jumping is an exercise for the reader, 
    but look into these packages which handle the dirty work</p>
    <ul>
        <li><a href="https://pypi.python.org/pypi/greenlet">https://pypi.python.org/pypi/greenlet</a> - interface for creating coroutine based microthreads
        <li><a href="http://eventlet.net/">http://eventlet.net/</a> - a concurrent networking library, based on greenlet.   Developed for Second Life
        <li><a href="http://www.gevent.org">http://www.gevent.org</a> - forked from eventlet. Built on top of greenlet and libevent, a portable event loop with strong OS support
    </ul>

</section>

<section class="slide">
    <h2>Distributed programming</h2>
    <p>A distributed system is one in which components located on networked computers communicate and coordinate their actions by passing messages</p>
    <p>There are lots of ways to do this at different layers. MPI, *-RPC, Pyro, ...
</section>

<section class="slide">
    <h2>Celery</h2>
    <p>"Celery is an asynchronous task queue/job queue based on distributed message passing"
    <p>Provides an API for defining tasks, and retrieving results from those tasks
    <p>Messages are passed via a "message broker", of which Celery supports several:
        <ul>
            <li>RabbitMQ (default)
            <li>Redis
            <li>MongoDB
            <li>Amazon SQS
            <li>...
        </ul>
    <p>Celery worker processes are run on compute nodes, while the main process farms jobs out to them.
    <a target="_blank" href="http://www.celeryproject.org/">http://www.celeryproject.org/</a>
</section>

<section class="slide">
    <h2>Celery in one minute</h2>
<pre><code>
# tasks.py

from celery import Celery

celery = Celery('tasks', backend="amqp", broker='amqp://guest@localhost//')

@celery.task
def add(x, y):
    return x + y
</code></pre>
<pre><code>
% celery -A tasks worker --loglevel=INFO -c 4
</code></pre>
<pre><code>
>>> from tasks import add
>>> result = add.delay(2,3)
>>> print result.get()
</code></pre>
</section>

<!--
<section class="slide">
    <h2>title</h2>
    <p>text</p>
</section>
-->

<section class="slide">
    <h1>Questions?</h1>
</section>

<!-- End slides. -->

<!-- Begin extension snippets. Add or remove as needed. -->

<!-- deck.navigation snippet -->
<a href="#" class="deck-prev-link" title="Previous">&#8592;</a>
<a href="#" class="deck-next-link" title="Next">&#8594;</a>

<!-- deck.status snippet -->
<p class="deck-status">
	<span class="deck-status-current"></span>
	/
	<span class="deck-status-total"></span>
</p>

<!-- deck.goto snippet -->
<form action="." method="get" class="goto-form">
	<label for="goto-slide">Go to slide:</label>
	<input type="text" name="slidenum" id="goto-slide" list="goto-datalist">
	<datalist id="goto-datalist"></datalist>
	<input type="submit" value="Go">
</form>

<!-- deck.hash snippet -->
<a href="." title="Permalink to this slide" class="deck-permalink">#</a>

<!-- End extension snippets. -->


<!-- Required JS files. -->
<script src="jquery-1.7.2.min.js"></script>
<script src="core/deck.core.js"></script>

<!-- Extension JS files. Add or remove as needed. -->
<script src="core/deck.core.js"></script>
<script src="extensions/hash/deck.hash.js"></script>
<script src="extensions/menu/deck.menu.js"></script>
<script src="extensions/goto/deck.goto.js"></script>
<script src="extensions/status/deck.status.js"></script>
<script src="extensions/navigation/deck.navigation.js"></script>
<script src="extensions/scale/deck.scale.js"></script>

<!-- Initialize the deck. You can put this in an external file if desired. -->
<script>
	$(function() {
		$.deck('.slide');
	});
</script>
</body>
</html>
